\documentclass[a4paper,12pt]{article}

% Sprachen und Zeichencodierung
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}

% Schrift und Typografie
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{parskip}

% Seitenlayout und Struktur
\usepackage[a4paper,margin=2.5cm]{geometry}
\usepackage{titlesec}
\usepackage{float}
\usepackage{tocloft}
\usepackage{longtable,tabu}

% Referenzen und Zitate
\usepackage[
    backend=bibtex,
    style=ieee,
    sorting=nyt,
    natbib=true,
    url=false,
    doi=true,
    eprint=false
]{biblatex}
\addbibresource{references.bib}

% Links
\usepackage[hidelinks]{hyperref}

% Abbildungen
\usepackage{graphicx}

% Nummerierung und Linien
\usepackage{lineno}

% Zitate und Sprachschnipsel
\usepackage{csquotes}

% Abkürzungen und Glossare
\usepackage[automake, acronym]{glossaries}
\makeglossaries

\newacronym{rpg}{RPG}{
engl. "role-playing games", sind ein Genre von Spielen,
in denen die Spieler in die Rolle eines imaginären Charakters schlüpfen
}

\newacronym{xp}{XP}{
engl. "experience points", sind ein Konzept in Spielen,
das den Fortschritt eines Charakters oder Spielers zeigt
}

\newacronym{api}{API}{
engl. "application programming interface", ist eine Sammlung von Definitionen
und Protokollen, die es Softwareanwendungen ermöglichen, miteinander zu
kommunizieren
}

\newacronym{crud}{CRUD}{
	engl. "Create, Read, Update, Delete", die Funktionen, die ein Nutzer benötigt, um Daten anzulegen und zu verwalten
}

\newacronym{ssr}{SSR}{
	engl. "Server Side Rendering", ist Technik, Webseiten auf dem Server zu rendern, bevor sie an den Client-Browser gesendet werden
}

\newacronym{ssl}{SSL}{
	engl. "Secure Sockets Layer", ein Protokoll, das die Sicherheit der Kommunikation über das Internet gewährleistet
}

\newacronym{json}{JSON}{
	engl. “JavaScript Object Notation" ist ein kompaktes Datenformat, das in einer leicht lesbaren Textform den Datenaustausch zwischen Anwendungen ermöglicht.
}

% Einstellungen für das Inhaltsverzeichnis
\setcounter{tocdepth}{2}

% Absatzformatierung
\setlength{\parindent}{0pt}

\onehalfspacing

\begin{document}

% Titelseite
\pagenumbering{gobble}
\begin{titlepage}
	\centering
	{\LARGE Siemens Energy - BETI 2024 \par}
	\vspace{0.5cm}
	{\Large Realisierung eines Webauftritts \par}
	\vspace{3.5cm}
	{\huge\bfseries Socialmedia RPG \par}
	{\huge\bfseries Echo \par}
	\vspace{3cm}
	{\Large\itshape Ogulcan Kuecuek \par}
	{\Large\itshape Leon Woenckhaus \par}
	{\Large\itshape Nick Hildebrandt \par}
	{\Large\itshape Aaron Turyabahika \par}
	{\Large\itshape Andre Seiler \par}
	\vfill
	{\large \today\par}
\end{titlepage}
\newpage

% Inhaltsverzeichnis
\pagenumbering{roman}
\tableofcontents
\newpage

% Abbildungsverzeichnis
\listoffigures
\newpage

% Abkürzungsverzeichnis
\printglossary[type=\acronymtype, title=Abkürzungsverzeichnis]
\newpage

% Inhalt
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Projektbeschreibung}
Das Social Media Projekt „Echo“ ist ein innovatives, kompetitives Social Media Netzwerk, das speziell für Gamer, Digital Natives und Content Creator entwickelt wurde. Echo kombiniert die Elemente traditioneller Social Media Plattformen wie Reddit mit Rollenspiel-Mechaniken (\gls{rpg}), um ein dynamisches und interaktives Nutzererlebnis zu schaffen.

Nutzer sammeln Erfahrungspunkte (\gls{xp}), indem sie Likes und Kommentare auf ihre Posts von anderen Nutzern erhalten. Diese \gls{xp} sind ein Maß für die Aktivität und Beliebtheit eines Nutzers innerhalb der Plattform. Zusätzlich zu den \gls{xp} können Nutzer durch sogenannte „Streaks“ weitere Erfahrungspunkte sammeln. Ein Streak entsteht, wenn ein Nutzer über mehrere aufeinanderfolgende Tage hinweg aktiv ist und regelmäßig Inhalte postet oder mit anderen interagiert. Je länger der Streak, desto höher die Belohnung.

Ebenfalls können Benutzer anderen Accounts folgen, um aus diesen personalisierte Inhalte zu bekommen und keine Neuigkeiten mehr zu verpassen. Dieser Wert an sogenannten Followern wird ebenfalls gezählt.

Die gesammelten Erfahrungspunkte ermöglichen es den Nutzern, ihr Profil und das Design der Website individuell anzupassen. Dies umfasst personalisierte Themes, exklusive Avatare und spezielle Layouts, die das Profil einzigartig machen. Ab einer gewissen Anzahl an \gls{xp} können Nutzer ihr Profilbild, Bannerbild und Hintergrundbild selbst wählen, was zusätzliche Individualisierungsmöglichkeiten bietet.

Ein weiteres zentrales Element von Echo sind die sogenannten Communities, auf denen sich Nutzer sammeln können (Beitreten) und diese Awards durch andere Benutzer verliehen bekommen können, die im Profil angezeigt werden. Auf Communities gibt es genauso wie bei Benutzern die Möglichkeit, Posts mit Kommentaren und Likes zu versehen. Dies fördert die Interaktion und das Gemeinschaftsgefühl innerhalb der Plattform.

Im Mittelpunkt von Echo stehen Gamification-Elemente, Gruppenzugehörigkeit und das Belohnungsgefühl. Nutzer werden durch kontinuierliche Belohnungen und Fortschritte motiviert, aktiv zu bleiben und sich in der Community zu engagieren.

\newpage
\subsection{Projektbegründung}
Das Social Media Projekt „Echo“ zeichnet sich durch seine einzigartigen Gamification- und Rollenspiel-Elemente (\gls{rpg}) aus, die es zu einem besonderen Sammelpunkt für Gamer und die restliche Internetkultur machen. Diese Elemente fördern nicht nur die Interaktivität und das Engagement der Nutzer, sondern schaffen auch ein dynamisches und wettbewerbsorientiertes Umfeld, das die Nutzer motiviert, aktiv zu bleiben und sich kontinuierlich weiterzuentwickeln.

Ein weiteres technisches Highlight von Echo ist der innovative Caching-Algorithmus, der sicherstellt, dass Bilder nicht doppelt gespeichert werden. Beim Hochladen von Bildern werden doppelte Dateien erkannt und durch einen Verweis auf das bereits vorhandene Bild ersetzt. Diese Methode spart nicht nur wertvolle Speicherressourcen, sondern trägt auch zur Schonung der Umwelt bei. Durch die Reduzierung des Speicherbedarfs wird der Energieverbrauch der Server gesenkt, was wiederum den CO2-Ausstoß verringert und somit einen positiven Beitrag zum Umweltschutz leistet. Laut einer Studie des Borderstep Instituts für Innovation und Nachhaltigkeit verursachen Rechenzentren in Deutschland jährlich etwa 13 Millionen Tonnen CO2-Emissionen \cite{borderstep2020}, was die Bedeutung ressourcenschonender Technologien unterstreicht.

Die Motivation für das Projekt war es, eine minimalistische und schnelle Plattform speziell für Gamer zu entwickeln, um die Gaming- und Internetkultur in einen diversifizierten multimedialen Austausch zu stellen. Echo kombiniert technologische Innovation mit einer klaren Zielgruppenausrichtung, um eine Plattform zu schaffen, die sowohl funktional als auch nachhaltig ist. Die Integration von Gamification- und RPG-Elementen macht Echo zu einem einzigartigen Erlebnis für Nutzer, während die ressourcenschonende Technologie die Umweltbelastung minimiert. Diese Kombination aus Innovation und Zielgruppenfokussierung macht Echo zu einer herausragenden Plattform im Bereich der sozialen Medien.

\subsection{Projektabgrenzung}
Das Social Media Projekt „Echo“ wird durch ein serverseitig gerendertes Frontend realisiert (\gls{ssr}), das eine nahtlose und schnelle Benutzererfahrung gewährleistet. Dazu wird eine API entwickelt, die Daten aus einer relationalen Datenbank über die CRUD-Operationen (\gls{crud}) zur Verfügung stellt. Diese Architektur ermöglicht eine effiziente und skalierbare Datenverwaltung, die den Anforderungen einer dynamischen Social Media Plattform gerecht wird.

Das Projekt wird umfassend dokumentiert, wie in diesem Dokument beschrieben, und zusätzlich durch eine Abschlusspräsentation ergänzt. Diese Präsentation wird die wichtigsten Aspekte und Ergebnisse des Projekts zusammenfassen und visuell ansprechend darstellen.

Für die Vorstellung des Projekts wird „Echo“ auf einem Server im Internet bereitgestellt und über eine eigene Domain mit einem entsprechenden SSL-Zertifikat ((\gls{ssl})) erreichbar gemacht. Dies stellt sicher, dass die Plattform sicher und zuverlässig zugänglich ist und den modernen Sicherheitsstandards entspricht.

\newpage
\section{Projektplanung}

Zu Beginn des Projekts haben wir uns als Gruppe zusammengefunden und die grundlegenden Ideen und Funktionalitäten auf mehreren Flipchartblättern diskutiert. In intensiven Debatten haben wir die verschiedenen Aspekte des Projekts durchgesprochen, um am Ende einen sehr abstrakten Mockup zu erstellen, der zeigte, wie unser Projekt aussehen sollte und welche Funktionen bzw. RPG-Elemente es enthalten sollte.

Anschließend haben wir diese Funktionen in kleinere Issues aufgeteilt, die wie folgt beschrieben und aufgebaut sind: Eine kurze, prägnante Beschreibung des vorgeschlagenen Features, die erklärt, was es neu macht und warum es sinnvoll ist. Eine Liste der konkreten Funktionen, die das Feature umfassen wird. Eine Beschreibung des idealen Nutzerflusses für dieses Feature, die erklärt, wie der Nutzer mit dem Feature interagiert. Eine Auflistung der Technologien, die für die Frontend-Implementierung verwendet werden, sowie spezielle Designanforderungen, wie z.B. die Verwendung von Icons. Eine Erklärung, wie die Benutzereinstellungen in der Datenbank gespeichert werden, z.B. durch ein neues Dokument pro Benutzer mit den entsprechenden Feldern, sowie spezifische Anforderungen an die Datenverarbeitung oder Sicherheit.

Diese Issues dienen dabei gleichzeitig auch als Basisdokumentation der Funktionalität, aus der wir dieses Dokument technisch ableiten. Die Dokumentation selbst sowie die Präsentation werden über die Git-Versionskontrolle verwaltet und über Issues getrackt. Diese Issues wurden dank Kategorien wie Kernfunktionalität, optionale Funktionalität, Backend-API und Frontend zugewiesen. Zudem konnten einige Issues andere voraussetzen, wie z.B. dass ein Login die Registrierung voraussetzt. Mehrere Issues bildeten dann Meilensteine, die wir datieren konnten.

Da wir eine agile Arbeitsweise nach Scrum verwenden, gibt es tägliche Standups, in denen jeder sagt, was er gerade getan hat, welche Probleme es dabei gab und was er als nächstes machen wird. Die Entwicklungsarbeit und Versionsverwaltung wird dann durch Git realisiert, mit der Cloud-Implementierung von GitHub, um den Entwicklungsstand aus allen Computern zu synchronisieren. Git ist ein verteiltes Versionskontrollsystem, das es uns ermöglicht, Änderungen am Code effizient zu verfolgen und zusammenzuführen. Damit es zu keinen Konflikten in der gleichzeitigen Bearbeitung von ein und derselben Datei durch mehrere Leute kommt, wurde für jede Aufgabe ein eigener Entwicklungszweig erstellt. Diese wurden nach Beendigung wieder in den Main-Zweig zurückimplementiert, um eine lauffähige Version unseres Projekts stets im Main zu behalten.

Um einen Überblick über laufende und abgeschlossene Aufgaben zu haben, wurde auf GitHub ein Kanban-Board eingerichtet (3 Spalten: Offen, In Bearbeitung und Fertig), bei dem erledigte Aufgaben nach gemeinsamer Bewertung und Verbesserung auf „Fertig“ gestellt wurden. Nachdem wir zunächst die Backend-API gemeinsam mit dem Frontend bearbeitet hatten, mussten wir aufgrund der verschiedenen domänenspezifischen Anforderungen unseren Entwicklungsprozess umstellen und das Frontend und Backend parallel, aber getrennt durch verschiedene Teammitglieder entwickeln, um das jeweilige Können optimal zu allocieren.

\subsection{Teamaufbau und Rollen}
\begin{enumerate}
    \item Projektmanagement
    \begin{itemize}
        \item Nick Hildebrandt
    \end{itemize}
    \item Dokumentation
    \begin{itemize}
    	\item Leon Woenckhaus
    \end{itemize}
    \item Präsentation
    \begin{itemize}
    	\item Aaron Turyabahika
    \end{itemize}
    \item Backend-API
    \begin{itemize}
        \item Nick Hildebrandt
        \item Leon Woenckhaus
    \end{itemize}
    \item Frontend
    \begin{itemize}
        \item Andre Seiler
        \item Ogulcan Kuecuek
    	\item Aaron Turyabahika
    \end{itemize}
    \item Deploayment und integration
    \begin{itemize}
        \item Nick Hildebrandt
    \end{itemize}
\end{enumerate}

\subsection{Ressourcenplanung}
Detaillierte Planung der benötigten Ressourcen
(Hard-/Software, Räumlichkeiten usw.).

Ggfs. sind auch personelle Ressourcen einzuplanen (z.B. unterstützende
Mitarbeiter).

Hinweis: Häufig werden hier Ressourcen vergessen, die als selbstverständlich
ange- sehen werden (z.B. PC, Büro).

\subsection{Kostenplanung}

\subsection{Zeitplanung}
Der Plan sieht vor, dass der Cold Freeze am 10. Februar 2025 und der Hard Freeze am 13. Februar 2025 stattfinden. Die Präsentation war ursprünglich für den 17. Februar 2025 zur Überprüfung angesetzt. Das korrigierte Präsentationsdatum ist nun der 20. Februar 2025, wobei der Cold Freeze auf den 13. Februar 2025 und der Hard Freeze auf den 16. Februar 2025 verschoben wurde.
Im Softwareentwicklungsprozess bezeichnet der Cold Freeze den Zeitpunkt, ab dem keine neuen Features mehr hinzugefügt werden. Der Fokus liegt ab diesem Zeitpunkt auf der Stabilisierung und Fehlerbehebung. Der Hard Freeze markiert den endgültigen Stopp aller Änderungen am Code, um sicherzustellen, dass die Software für die Veröffentlichung vorbereitet ist.

Das Projekt wird innerhalb eines festgelegten Zeitrahmens durchgeführt, wobei die tägliche Arbeitszeit auf 8 Stunden pro Person begrenzt ist. Der Projektumfang wurde so geplant, dass die reguläre Arbeitszeit von 8 Stunden pro Tag pro Person ausreicht, um das Projekt abzuschließen. Sollten Teammitglieder bereit sein, zusätzlichen Aufwand zu investieren, können weitere Features und Verbesserungen implementiert werden, die über die ursprünglichen Anforderungen hinausgehen.

Zunächst wurde das Geschäftsmodell und die Grundidee unseres Projektes im Rahmen des betriebswirtschaftlichen Unterrichts in der Woche vom 2. bis 6. Dezember 2024 in Form eines Business Model Canvas geplant. Im Januar wurde viel Zeit in die detaillierte Planung des Projekts und des Projektumfangs investiert. Die Umsetzung begann in der Woche vom 13. bis 19. Januar 2025. In dieser Phase wurde die Grundidee spezifiziert, technische Fähigkeiten erlernt und kollaborative Arbeitsprozesse mit GitHub eingerichtet.

Von 20. Januar bis 12. Februar 2025 erfolgte die technische Umsetzung von Frontend und Backend, wobei auftretende Probleme behandelt und Funktionen weiter spezifiziert wurden. In der Woche vom 13. bis 19. Februar 2025 wurde die Projektdokumentation erstellt und die Präsentation durch die jeweils verantwortlichen Teammitglieder vorbereitet. Gleichzeitig wurde die fertige Version getestet und gemäß unserem Deployment-Plan auf einem Server bereitgestellt.

%Tabellenverzeichnis? 
\newpage
\begin{longtable}{|p{4cm}|p{11cm}|}
	\hline
	\textbf{Zeitraum} & \textbf{Aktivitäten} \\
	\hline
	02.12.2024 - 06.12.2024 & Planung des Geschäftsmodells und der Grundidee im betriebswirtschaftlichen Unterricht in Form eines Business Model Canvas \\
	\hline
	Januar 2025 & Detaillierte Planung des Projekts und des Projektumfangs \\
	\hline
	13.01.2025 - 19.01.2025 & Spezifizierung der Grundidee, Erlernen technischer Fähigkeiten und Einrichtung kollaborativer Arbeitsprozesse mit GitHub \\
	\hline
	20.01.2025 - 12.02.2025 & Technische Umsetzung von Frontend und Backend, Behandlung auftretender Probleme und weitere Spezifizierung der Funktionen \\
	\hline
	13.02.2025 - 19.02.2025 & Erstellung der Projektdokumentation und Vorbereitung der Präsentation durch die jeweils verantwortlichen Teammitglieder, Testen der fertigen Version und Bereitstellung auf einem Server gemäß dem Deployment-Plan \\
	\hline
	10.02.2025 & Cold Freeze: Keine neuen Features werden hinzugefügt, Fokus auf Stabilisierung und Fehlerbehebung \\
	\hline
	13.02.2025 & Hard Freeze: Endgültiger Stopp aller Änderungen am Code, um die Software für die Veröffentlichung vorzubereiten \\
	\hline
	16.02.2025 & Hard Freeze (korrigiert): Endgültiger Stopp aller Änderungen am Code \\
	\hline
	20.02.2025 & Präsentation des Projekts \\
	\hline
\end{longtable}

\textit{
Gant Diagramm hier, Tabelle schöner
}

\newpage \section{Zielplattform und Implementierung}
Zur Auswahl der Zielplattform gehören unter anderem die Programmiersprache, die Datenbank, Client/Server-Architektur und die Hardware. 

Unsere Zielplattform für die Serverseite ist Linux, da Linux-basierte Server weit verbreitet sind. Für den Webbrowser setzen wir auf Gecko, WebKit und V8 für serverseitiges Rendering. Das Backend wird mit Node.js auf Linux betrieben.

Node.js gilt als Goldstandard (Quelle hier). Wir haben uns für Node.js statt Deno entschieden, da es zuvor Kompatibilitätsprobleme mit Deno gab. Node.js ist jedoch besser etabliert und verfügt aufgrund seiner längeren Existenz über mehr Dokumentation. Außerdem ist Node.js zum Zeitpunkt des Projektbeginns besser mit Nuxt kompatibel.


zur Auswahl der Zielplattform (u.a. Programmiersprache, Datenbank,
Client/Server, Hardware).
Zielplatform: Linux 
Webbrowser 
gecko, webkit, v8 serverside rendered 
nodejs Linux backend
was ist node node goldstandard (quelle hier) 
node.js statt deno: Zuvor mit deno kompalitbitätsproblem. Node allerdings besser etabliert, mehr Dokumentation aufgrund längerem bestehen. Node.js ist ausserdem besser kompatibel mit Nuxt zum Zeitpunkt des Projektbeginns. 


\subsection{Architekturdesign}
Für unser Projekt haben wir uns für die Nutzung des Nuxt.js-Frameworks entschieden. Nuxt.js ist ein leistungsstarkes Framework, das auf Vue.js aufbaut und die Entwicklung von serverseitig gerenderten (\gls{ssl}) und statisch generierten Anwendungen vereinfacht. Durch diese Trennung wird die Wartbarkeit und Erweiterbarkeit der Anwendung erheblich verbessert. Dies ist für uns von großem Interesse, da wir unser Projekt so aufsetzen wollen, dass wir es in der Zukunft um weitere Features erweitern können. So können wir zunächst den Social Media Aspekt des Projekts umsetzen, um darauf die Role-Playing-Game (\gls{rpg}) Elemente langsam aufzubauen. Dadurch können wir nach der Fertigstellung des Social Media Grundgerüsts jederzeit einen funktionierenden Prototypen präsentieren.

Unsere Wahl für das Framework fiel auf Nuxt.js, da es ein leistungsstarkes Framework ist. Es baut auf Vue.js auf und vereinfacht die Entwicklung von serverseitig gerenderten (\gls{ssr}) und statisch generierten Anwendungen. Ein zentrales Konzept in Nuxt.js sind die Komponenten. Vue-Komponenten ermöglichen es, die Anwendung in wiederverwendbare und isolierte Module zu unterteilen. Diese Module können mehrfach verwendet und für verschiedene Anwendungsfälle angepasst werden, was die Entwicklung effizienter und die Codebasis übersichtlicher macht. Die Komponenten erlauben uns auch, das Projekt effizient zu erweitern. Daher eignet sich Nuxt.js ideal als Framework für unsere Anforderungen an das Projekt.

Unsere Wahl viel auf Nuxt über andere ähnlich aufgebaute Frameworks wie Next aufgrund folgender Auswahlkriterien: 
Nuxt.js bietet umfassende Unterstützung für serverseitiges Rendering und statische Seitengenerierung, was es zu einer idealen Wahl für Fullstack-Anwendungen macht.
Für Nuxt existiert eine ausführliche Dokumentation und eine Vielzahl an Tutorials. Der Einstieg und die kontinuierliche Weiterentwicklung der Anwendung wird dadurch vereinfacht und Gruppenmitglieder mit weniger Programmier- Erfahrung können schneller in den Workflow eingebunden werden. 
Nuxt.js ist kompatibel mit den bestehenden Technologien und Umgebungen, die wir nutzen möchten, was eine nahtlose Integration und Migration ermöglicht. 

Ggfs. Bewertung und Auswahl von verwendeten Frameworks sowie ggfs. eine kurze
Einführung in die Funktionsweise des verwendeten Frameworks.

\textit{Prisma/SQLite Backend }

Für die Umsetzung des Backends ist eine Datenbank unverzichtbar. SQLite ist für unser Projekt besonders gut geeignet, da es auch bei einer großen Anzahl von Einträgen und Abfragen eine hohe Geschwindigkeit und Effizienz bietet. Allerdings kann die direkte Einbindung von SQLite in PHP-Anwendungen die Anwendung anfällig für SQL-Injections machen. Um dieses Sicherheitsrisiko zu minimieren, haben wir uns entschieden, ein Object-Relational Mapping (ORM) zu verwenden.\textit{(ORM Abkürzung in document handeln)}
Aufgrund der vorhandenen Kompatibilität mit Nuxt.js und Node.js haben wir uns für Prisma als ORM entschieden. Prisma fungiert als eine Schicht zwischen der Datenbank und der Anwendung, die es ermöglicht, Datenbankabfragen sicher und effizient durchzuführen. Es bietet eine typsichere API, die die Entwicklung vereinfacht und gleichzeitig die Sicherheit erhöht, indem es SQL-Injections verhindert. Prisma unterstützt zudem die Migration und Verwaltung der Datenbankstruktur, was die Wartung und Weiterentwicklung der Anwendung erleichtert.

Im Rahmen des Deployments wird Nginx als Reverse HTTPS Proxy eingesetzt. Nginx übernimmt dabei die Aufgabe, eingehende Anfragen an die entsprechenden Backend-Server weiterzuleiten und sorgt so für eine effiziente Lastverteilung und erhöhte Sicherheit. Darüber hinaus wird Nginx auch für die Verwaltung der SSL-Zertifikate zuständig sein, um eine sichere HTTPS-Verbindung zu gewährleisten.\textit{(was ist nginx quelle:https://nginx.org/en/)}

Für die automatische Verwaltung und Erneuerung der SSL-Zertifikate nutzen wir das ACME-Protokoll (Automated Certificate Management Environment). ACME ist ein Protokoll, das von der Internet Security Research Group (ISRG) entwickelt wurde und es ermöglicht, SSL/TLS-Zertifikate automatisch zu beziehen und zu erneuern. Dies reduziert den administrativen Aufwand und stellt sicher, dass unsere Zertifikate stets aktuell und sicher sind.(\textit{acme acronym in document handeln, absatz review Nick})

\subsection{Benutzeroberfläche}
\textit{Entscheidung für die gewählte
Benutzeroberfläche (z.B. GUI, Webinterface).Beschreibung des visuellen Entwurfs der konkreten Oberfläche (z.B. Mockups,
Menü- führung). Inspirationen: Instagram, Bluesky, Steam, Discord}
 
Der strukturelle Aufbau unserer Seite ist von verschiedenen Social-Media-Plattformen inspiriert. Die Idee, den Nutzern zu erlauben, Communities zu erstellen, ist vom Prinzip der sogenannten Subreddits abgeleitet. Auf der Forenseite Reddit können Subsites erstellt werden, die sich thematisch voneinander abgrenzen und jeweils eigene Regeln haben. Als klassische Forenseite ist Reddit jedoch nicht besonders intuitiv zu bedienen.

Wir haben uns außerdem Discord angesehen, eine Plattform, die eine eigene Desktop-Applikation bietet und vor allem als Voice- und Text-Chat-Programm bekannt ist. Discord ermöglicht es den Nutzern, ihre eigenen sogenannten Server zu erstellen, was besonders in der Gaming-Community ein viel genutztes Feature ist. Allerdings ist es für normale Nutzer, die wenig über die Community-basierte Natur der Server wissen, nicht offensichtlich, dass ein großer Social-Media-Aspekt in dieser Chat-Anwendung integriert ist.

Beide Seiten haben also ihre Mankos bei der Benutzerfreundlichkeit. Bei Instagram hat der Nutzer über eine Leiste einfachen Zugriff auf seinen Feed, sein Profil, die Suche und die Erkundung. Diese Simplizität macht Instagram sehr benutzerfreundlich. Wir wollten durch den Einsatz eines festen Headers auf unserer Seite diese Nutzerfreundlichkeit nachahmen. Die Communities sowie die Community-Suche und -Erkundung sollen direkt eingebunden sein, sodass es für die Nutzer einfach ist, diese Features zu finden und zu bedienen. 

Komponenten der Seite von anderen Seiten inspriert und möglichs user friendly gemacht; Profil inspo twitter, follower list Insta, eigenene Ideen zb: Badge hinzufügen, Inspo für badges an sich Steam 

Tatsächliche Umsetzung by 'what do we need' Nuxt UI elemente statt CSS 

Icons statt text simpler nicht schreiben sondern zeigen Zahnrad einstellungen, plus hinzufügen, Pictogramme simple modern 

Steam RPG inspo, Motivation (alle von uns steam user, steam als mehr social statt game installer website) 

\textit{
Ggfs. Erläuterung von angewendeten Richtlinien zur Usability und Verweis auf
Corpo- rate Design.}

\subsection{Datenmodell}
Entwurf/Beschreibung der Datenstrukturen (z.B. ERM
und/oder Tabellenmodell, XML- Schemas) mit kurzer Beschreibung der wichtigsten
(!) verwendeten Entitäten. ERM einfügen 
Relationelles Datenbankmodell 

\textit{Beschreibung der angelegten Datenbank (z.B. Generierung von SQL aus Modellierungswerkzeug oder händisches Anlegen), XML-Schemas usw.}

Unsere Datenbank wurde mit Prisma als Object-Relational Mapping (ORM) Tool erstellt und migriert. Jedes in unserem Schema geplante Tabellenobjekt wurde als Modell in Prisma definiert, was eine strukturierte und effiziente Datenverwaltung ermöglicht. Ein Vorteil von Prisma ist die automatische Generierung von Zwischentabellen durch die Verwendung von @relations, was den Entwicklungsprozess erheblich vereinfacht und beschleunigt. Als Backend für das ORM dient SQLlite, das eine zuverlässige und performante Grundlage für unsere Datenbankoperationen bietet. Diese Kombination aus Prisma und SQLlite gewährleistet eine robuste und skalierbare Datenbanklösung, die sowohl den aktuellen als auch zukünftigen Anforderungen unseres Projekts gerecht wird.

Um die wichtigsten Beziehungen in unserem Social-Media-Projekt darzustellen, sind die Modelle für Benutzer, Post, Community und Kommentare von zentraler Bedeutung. Die Benutzertabelle enthält beispielsweise eine eindeutige ID, die jeden Nutzer identifiziert, sowie die Nutzerdaten wie Name und E-Mail-Adresse. Darüber hinaus gibt es Querverweise auf andere Tabellen durch Foreign Keys, die beispielsweise auf die Posts eines Nutzers verweisen. Die Post-Tabelle weist für jeden Post ebenfalls eine eindeutige ID auf und enthält einen Foreign Key, der auf den Autor des Posts verweist. Prisma erstellt automatisch Zwischentabellen zwischen diesen Tabellen, in denen die Post-IDs und Benutzer-IDs hinterlegt werden. Diese automatische Generierung von Zwischentabellen durch Prisma gewährleistet eine effiziente und strukturierte Verwaltung der Datenbankbeziehungen, was die Handhabung und Abfrage unserer Social-Media-Daten erheblich vereinfacht. 


\subsection{Datenzugriff und Backend-API Routen}
\textit{(to be reworked)} 
Die Backend-API (\gls{api}) dient als zentrale Schnittstelle zwischen dem Frontend und dem Backend unserer Anwendung. Ihre Hauptaufgabe besteht darin, Daten wie Profile, Communities und Posts aus der Datenbank abzurufen und diese dem Frontend zur Verfügung zu stellen. Die API definiert dabei klar strukturierte Routen, die festlegen, wie diese Datenabfragen erfolgen und welche Informationen abgerufen werden können. Wir verwenden eine RESTful API (Representational State Transfer), eine Art von Web-API, die auf den Prinzipien des REST-Architekturstils basiert. RESTful APIs nutzen HTTP-Anfragen, um auf Ressourcen zuzugreifen und diese zu manipulieren. Diese Ressourcen werden durch eindeutige URLs identifiziert und können in verschiedenen Formaten wie (\gls{json}) oder XML dargestellt werden. Unsere API übergibt JSON Objekte. 

Durch die Nutzung der API-Routen wird die Integration ins Frontend erheblich vereinfacht. Entwickler müssen keine direkten SQL-Abfragen schreiben oder tiefgehende technische Kenntnisse besitzen, um auf die benötigten Daten zuzugreifen. Stattdessen können sie die vorgegebenen API-Endpunkte nutzen, um benutzerfreundlich und effizient die gewünschten Informationen zu erhalten und anzuzeigen. 

Ein wesentliches Merkmal einer RESTful API ist ihre Statelessness, was bedeutet, dass jede Anfrage vom Client an den Server alle notwendigen Informationen enthält, um sie zu verstehen und zu verarbeiten. Dies erleichtert die Skalierbarkeit und Zuverlässigkeit der API. Darüber hinaus verwenden RESTful APIs standardisierte HTTP-Methoden wie GET, POST, PUT und DELETE, um \gls{crud}-Operationen (Create, Read, Update, Delete) auf den Ressourcen durchzuführen. 

\textit{(Jeuses chreisis umsortieren und aufdröseln (up))}

\textit{Systemkontext: Darstellung, wie das Backend in die Gesamtarchitektur
eingebunden ist (z. B. Diagramm mit Datenbank, Frontend, API-Gateway).
Technologiestack: Beschreibung der eingesetzten Technologien (z. B.
Programmiersprache, Frameworks, Datenbank).
Designmuster: Falls zutreffend, z. B. REST, Microservices, etc. }



\textit{Request/Response-Formate: HTTP-Methoden (GET, POST, PUT, DELETE).
Beispielanfragen und -antworten (JSON, XML, etc.).  Fehlercodes und
Fehlermeldungen.}

Um unsere API nutzen zu können, verlassen wir uns auf gängige HTTP-Methoden. HTTP-Methoden sind grundlegende Operationen, die im Hypertext Transfer Protocol (HTTP) verwendet werden, um Anfragen zwischen einem Client und einem Server zu definieren. Die vier häufigsten HTTP-Methoden sind GET, POST, PUT und DELETE. Unsere Routen benutzen diese Methoden, um Daten aus dem Backend ins Frontend zu übertragen oder umgekehrt neue Daten vom Frontend ins Backend weiterzuleiten.
 
Die GET-Methode wird verwendet, um Daten vom Server anzufordern. Eine GET-Anfrage ruft Informationen ab, ohne den Zustand des Servers zu verändern. Beispielsweise wird eine GET-Anfrage verwendet, um eine Webseite oder eine API-Ressource abzurufen.
Mit der POST-Methode werden Daten an den Server gesendet, um eine neue Ressource zu erstellen. Diese Methode wird häufig verwendet, um Formulardaten oder andere Informationen an den Server zu übermitteln, die dann verarbeitet und gespeichert werden.
Die PUT-Methode wird verwendet, um eine vorhandene Ressource auf dem Server zu aktualisieren oder zu ersetzen. Im Gegensatz zu POST, das eine neue Ressource erstellt, wenn sie nicht existiert, überschreibt PUT die vorhandene Ressource vollständig mit den gesendeten Daten.
Die DELETE-Methode wird verwendet, um eine Ressource auf dem Server zu löschen. Eine DELETE-Anfrage entfernt die angegebene Ressource und verändert somit den Zustand des Servers.

Unsere API Endpunkte können mit diesen Methoden die Daten Serverseitig auf der Datenbank verändern, oder von der Datenbank abrufen. So kann zum Beispiel über die /users Route bestimmte Daten von den Usern über GET abgerufen werden, oder ein neuer User mit POST erstellt werden. Wenn sich jemand zum ersten mal über das Frontend registriert wird der Account über POST in der Datenbank angelegt. 

\textit{Endpunkte: Liste der API-Endpunkte (z. B. GET /users, POST /orders).
Beschreibung des Zwecks jedes Endpunkts.}

Authentifizierung und Autorisierung: Beschreibung des Sicherheitskonzepts (z. B.
OAuth, API-Keys).  Zugriffsbeschränkungen und Rollen.

\newpage \section{Abnahmephase}
Welche Tests (z.B. Unit-, Integrations-,
Systemtests) wurden durchgeführt und welche Ergebnisse haben sie geliefert
(z.B. Logs von Unit Tests, Testprotokolle der Anwen- der)?

\subsection{Bereitstellung}
Welche Schritte waren zum Deployment der Anwendung
nötig und wie wurden sie durchgeführt (automatisiert/manuell)?

\subsection{Fazit}
Wurde das Projektziel erreicht und wenn nein, warum nicht?

Ist der Auftraggeber mit dem Projektergebnis zufrieden und wenn nein, warum
nicht?

Wurde die Projektplanung (Zeit, Kosten, Personal, Sachmittel) eingehalten oder
haben sich Abweichungen ergeben und wenn ja, warum?

Hinweis: Die Projektplanung muss nicht strikt eingehalten werden. Vielmehr sind
Ab- weichungen sogar als normal anzusehen. Sie müssen nur vernünftig begründet
wer- den (z.B. durch Änderungen an den Anforderungen, unter-/überschätzter
Aufwand).

% Literaturverzeichnis
\newpage
\printbibliography

\end{document}
